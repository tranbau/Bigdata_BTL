{
  "metadata": {
    "name": "Untitled Note 1",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\r\n\r\nfrom pyspark.sql import SparkSession\r\nfrom datetime import datetime, timedelta\r\nimport random\r\n\r\nspark \u003d SparkSession.builder.appName(\u0027SparkByExamples.com\u0027).getOrCreate()\r\n\r\ncolumns \u003d [\"date\", \"price\"]\r\n\r\ndata \u003d []\r\nstart_date \u003d datetime(2023, 1, 1)\r\nfor i in range(100):\r\n    price \u003d round(random.uniform(10, 100), 2)\r\n    data.append((start_date.strftime(\"%Y-%m-%d\"), price))\r\n    start_date +\u003d timedelta(days\u003d1)\r\n\r\n# Create DataFrame with inferred schema\r\ndf \u003d spark.createDataFrame(data, schema\u003dcolumns)\r\n\r\ndf.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Cumulative Moving Average\n## $$ \\text{CMA}(k) \u003d \\frac{x_1 + x_2 + \\ldots + x_k}{k} $$\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n%matplotlib inline\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ndef cumulative_moving_average(df):\n    window_spec \u003d Window.orderBy(\"date\").rowsBetween(Window.unboundedPreceding, 0) # Tính từ đầu\n    df \u003d df.withColumn(\u0027cma\u0027, F.round(F.avg(\"price\").over(window_spec), 2))\n    df_cma \u003d df.select(\"date\", \"price\", \"cma\")\n    \n    return df_cma\n\ndf_cma \u003d cumulative_moving_average(df)\ndf_cma.show(truncate\u003dFalse)\n\n#Convert Spark DataFrame to Pandas DataFrame for plotting\npandas_df \u003d df_cma.toPandas()\npandas_df[\u0027date\u0027] \u003d pd.to_datetime(pandas_df[\u0027date\u0027])\n\n# Plotting price and sma on the same plot using Matplotlib\nplt.figure(figsize\u003d(22, 8))\nplt.plot(pandas_df[\u0027date\u0027], pandas_df[\u0027price\u0027], label\u003d\u0027Price\u0027)\nplt.plot(pandas_df[\u0027date\u0027], pandas_df[\u0027cma\u0027], label\u003d\u0027CMA\u0027)\nplt.xlabel(\u0027Date\u0027)\nplt.ylabel(\u0027Value\u0027)\nplt.title(\u0027Price and Cumulative Moving Average (CMA)\u0027)\nplt.legend()\nplt.xticks(rotation\u003d45)\n\nplt.show()\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Simple Moving Average\n## $$ \\text{SMA}(k) \u003d \\frac{x_{k-T+1} + x_{k-T+2} + \\ldots + x_k}{T} $$\n### Với T là  chu kì tính (tông số phiên tính : các phiên trước + phiên hiện tại)\n\n\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\r\n%matplotlib inline\r\nfrom pyspark.sql import functions as F\r\nfrom pyspark.sql.window import Window\r\nimport matplotlib.pyplot as plt\r\nimport pandas as pd\r\n\r\ndef simple_moving_average(df, period\u003d3):\r\n    window_spec \u003d Window.orderBy(\"date\").rowsBetween(1 - period, 0)\r\n    df \u003d df.withColumn(\"sma\", F.round(F.avg(\"price\").over(window_spec), 2))\r\n    df_sma \u003d df.select(\"date\", \"price\", \"sma\")\r\n    return df_sma\r\n\r\nperiod_sma \u003d int(z.input(\"Enter SMA period: \", 3))  \r\ndf_sma \u003d simple_moving_average(df, period_sma)\r\ndf_sma.show(truncate\u003dFalse)\r\n# df_sma.createOrReplaceTempView(\u0027sma\u0027) to switch to sql\r\n\r\n# Convert Spark DataFrame to Pandas DataFrame for plotting\r\npandas_df \u003d df_sma.toPandas()\r\npandas_df[\u0027date\u0027] \u003d pd.to_datetime(pandas_df[\u0027date\u0027])\r\n\r\n# Plotting price and sma on the same plot using Matplotlib\r\nplt.figure(figsize\u003d(22, 8))\r\nplt.plot(pandas_df[\u0027date\u0027], pandas_df[\u0027price\u0027], label\u003d\u0027Price\u0027)\r\nplt.plot(pandas_df[\u0027date\u0027], pandas_df[\u0027sma\u0027], label\u003d\u0027SMA\u0027)\r\nplt.xlabel(\u0027Date\u0027)\r\nplt.ylabel(\u0027Value\u0027)\r\nplt.title(\u0027Price and Simple Moving Average (SMA)\u0027)\r\nplt.legend()\r\nplt.xticks(rotation\u003d45)\r\n\r\nplt.show()\r\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "\r\n# Exponential Moving Average\r\n\r\n## $$ \\text{EMA}_k \u003d x_0  \\text{ if }  k \u003d 0  \\text{ else } \u003d a \\cdot x_k + (1 - a) \\cdot \\text{EMA}_k  \\text{ }_1 $$\r\n## Biểu thức biến đối : $$ y_k \u003d \\frac{x_k + (1-a) \\cdot x_{t-1} + (1-a)^2 \\cdot x_{k-2} + ... + (1-a)^n \\cdot x_{t-n} }{1 + (1-a) + (1-a)^2 + ... + (1-a)^n} $$\r\n### Với a : $$\\frac{2}{T + 1} $$ \r\n###     T : chu kì tính (12)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n%matplotlib inline\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef ema_calculate(t, values, N):\n    alpha \u003d 2.0 / (N + 1) # Chỉ số alpha\n    adjusted_weights \u003d [pow(1 - alpha, t - index) for index in range(t + 1)] # [(1-a)^0 , (1-a)^1 , (1-a)^2 , ... , (1-a)^n]\n    numerator \u003d sum(map(lambda x, y: x * y, adjusted_weights, values[:t + 1])) # tử số , nhân 2 phần tử tương ứng 2 mảng và tính tổng các kết quả\n    denomiator \u003d sum(adjusted_weights)\n    result \u003d  numerator / denomiator\n    \n    return  result\n\ndef exponential_moving_average(df, period \u003d 10):\n    column \u003d \"price\"\n    orderByColumn \u003d \"date\"\n    \n    ema_udf \u003d F.udf(ema_calculate)\n    window_spec \u003d Window.orderBy(orderByColumn)\n    df_with_t \u003d df.withColumn(\"t\", F.row_number().over(window_spec) - 1)\n    df_ema \u003d df_with_t.withColumn(\"ema\", ema_udf(F.col(\"t\"), F.collect_list(column).over(window_spec), F.lit(period))).drop(\"t\")\n    df_ema \u003d df_ema.select(\"date\", \"price\", \"ema\")\n    \n    return df_ema\n\nperiod_ema \u003d int(z.input(\"Enter SMA period: \", 12))  \ndf_ema \u003d exponential_moving_average(df, period_ema)\ndf_ema.show(truncate\u003dFalse)\n\n#Convert Spark DataFrame to Pandas DataFrame for plotting\npandas_df \u003d df_ema.toPandas()\npandas_df[\u0027date\u0027] \u003d pd.to_datetime(pandas_df[\u0027date\u0027])\n\n# Plotting price and sma on the same plot using Matplotlib\nplt.figure(figsize\u003d(22, 8))\nplt.plot(pandas_df[\u0027date\u0027], pandas_df[\u0027price\u0027], label\u003d\u0027Price\u0027)\nplt.plot(pandas_df[\u0027date\u0027], pandas_df[\u0027ema\u0027], label\u003d\u0027EMA\u0027)\nplt.xlabel(\u0027Date\u0027)\nplt.ylabel(\u0027Value\u0027)\nplt.title(\u0027Price and Exponential Moving Average (EMA)\u0027)\nplt.legend()\nplt.yticks(np.linspace(0, 100, 10))\nplt.xticks(rotation\u003d45)\n\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Relative Strength - Relative Strength Index\n\n## $$ \\text{RS} \u003d \\frac{\\text{AVG(GAIN)}_T}{\\text{AVG(LOSS)}_T} $$\n## $$ \\text{RSI} \u003d 100 - \\frac{100}{1 + \\text{RS} } $$\n### Với: T : chu kì tính (14)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n%matplotlib inline\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.window import Window\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\ndef relative_strength_index(df, period \u003d 14):\n    # Tính độ tăng/giảm giữa 2 phiên liên tiếp\n    window_spec \u003d Window.orderBy(\u0027date\u0027)\n    df_dis \u003d df.withColumn(\u0027dis\u0027,F.col(\u0027price\u0027) - F.lag(F.col(\u0027price\u0027), 1).over(window_spec))\n    df_dis \u003d df_dis.withColumn(\u0027up\u0027, F.when(F.col(\u0027dis\u0027) \u003e\u003d 0, F.col(\u0027dis\u0027)).otherwise(None))\n    df_dis \u003d df_dis.withColumn(\u0027down\u0027, F.when(F.col(\u0027dis\u0027) \u003c 0, -F.col(\u0027dis\u0027)).otherwise(None))\n    df_dis \u003d df_dis.drop(\u0027dis\u0027)\n    \n    # Tính TBC tăng/giảm theo chu kì (14) và chia tỉ lệ ra rs\n    df_avg_dis \u003d df_dis.withColumn(\u0027avg_up\u0027, F.when(F.row_number().over(Window.orderBy(\u0027date\u0027)) \u003e period,\n                                              F.avg(\u0027up\u0027).over(window_spec)).otherwise(None))\n    df_avg_dis \u003d df_avg_dis.withColumn(\u0027avg_down\u0027, F.when(F.row_number().over(Window.orderBy(\u0027date\u0027)) \u003e period,\n                                              F.avg(\u0027down\u0027).over(window_spec)).otherwise(None))\n    df_rs \u003d df_avg_dis.withColumn(\u0027rs\u0027,F.round(F.col(\"avg_up\") / F.col(\"avg_down\"),2))\n    \n    # Tính rsi từ rs\n    df_rsi \u003d df_rs.withColumn(\u0027rsi\u0027, 100 - 100 / (1 + F.col(\u0027rs\u0027)))\n    df_rsi \u003d df_rsi.withColumn(\u0027rsi\u0027, F.round(F.col(\u0027rsi\u0027), 2))\n    df_rsi \u003d df_rsi.select(\"date\", \"price\", \"rsi\")\n    \n    return df_rsi\n\nperiod_rsi \u003d int(z.input(\"Enter RSI period: \", 14))  \ndf_rsi \u003d relative_strength_index(df, period_rsi)\ndf_rsi.show(truncate\u003dFalse)\n\n#Convert Spark DataFrame to Pandas DataFrame for plotting\npandas_df \u003d df_rsi.toPandas()\npandas_df[\u0027date\u0027] \u003d pd.to_datetime(pandas_df[\u0027date\u0027])\n\n# Plotting price and sma on the same plot using Matplotlib\nplt.figure(figsize\u003d(22, 8))\nplt.plot(pandas_df[\u0027date\u0027], pandas_df[\u0027rsi\u0027], label\u003d\u0027RSI\u0027)\nplt.xlabel(\u0027Date\u0027)\nplt.ylabel(\u0027RSI\u0027)\nplt.title(\u0027Price and Relative Strength Index (RSI)\u0027)\nplt.legend()\n# plt.yticks(np.linspace(0, 100, 10))\nplt.xticks(rotation\u003d45)\n\nplt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": ""
    }
  ]
}